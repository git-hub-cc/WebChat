好的，我们从头开始，详细描述建立语音通话、通话中交互（包括自适应音频质量调整）以及挂断通话的完整中文路径，避免使用“与之前描述相同”的说法，并确保所有阶段的内容都得到充分展现。

**前提条件：**

*   用户 A 希望与用户 B 进行语音通话。
*   双方均在线并已连接到信令服务器。
*   双方之间已建立或可以建立基础的 WebRTC 数据通道连接。

**阶段零：连接建立 (用户 A 与 用户 B 之间的数据通道)**

1.  **WebSocket 连接 (双方):**
    *   `AppInitializer.js` (应用初始化器) 在应用启动时调用 `ConnectionManager.connectWebSocket()`。
    *   `ConnectionManager.js` (连接管理器) 中的 `connectWebSocket()` 方法负责：
        *   建立与 `Config.server.signalingServerUrl` (信令服务器地址) 的 WebSocket 连接。
        *   WebSocket `onopen` (连接成功时) 事件触发：
            *   设置 `isWebSocketConnected = true` (WebSocket 连接状态为真)。
            *   调用 `registerUser()` 方法。
                *   `registerUser()`: 向信令服务器发送一个 `{ type: 'REGISTER', userId: UserManager.userId }` 类型的消息，其中 `UserManager.userId` 是当前用户的 ID。
            *   启动 `startHeartbeat()` 方法，定期向服务器发送 PING 消息以保持连接活跃。
            *   `LayoutUIManager.updateConnectionStatusIndicator('信令服务器已连接。')` 更新全局连接状态指示器。
        *   WebSocket `onmessage` (收到消息时) 事件监听器，用于处理来自信令服务器的各种消息。
        *   WebSocket `onclose` (连接关闭时) 和 `onerror` (发生错误时) 事件处理器，负责处理连接断开、错误，并根据 `Config.reconnect` 的配置尝试自动重连。

2.  **添加联系人 (如果用户 B 不是用户 A 的联系人):**
    *   用户 A 可能通过 `ModalUIManager.js` (模态框UI管理器) 提供的“新建联系人/群组模态框”来添加用户 B。
    *   在模态框中点击“**确认添加联系人**”按钮 (`confirmNewContactBtn`) 会触发事件。
    *   该事件调用 `UserManager.addContact(peerId, peerName, establishConnection = true)` 方法。
    *   `UserManager.js` (用户管理器) 中的 `addContact(id, name, establishConnection = true)` 方法：
        *   将用户 B 的信息 (ID, 名称等) 保存到本地联系人列表 (`this.contacts`) 和 IndexedDB 数据库。
        *   如果 `establishConnection` 参数为 `true` (默认)，则调用 `ConnectionManager.createOffer(id, { isSilent: true })` 尝试以静默方式与用户 B 建立 WebRTC 数据通道连接。

3.  **WebRTC 数据通道连接协商 (以用户 A 主动连接用户 B 为例，主要在 `ConnectionManager.js` 中进行):**
    *   `createOffer(targetPeerId = UserB_ID, options = {isSilent: true, isVideoCall: false})`:
        *   调用 `pc = this.initConnection(targetPeerId, false)` 初始化或获取一个 `RTCPeerConnection` 实例 (`pc`)。
            *   `initConnection` 内部会为 `pc` 设置必要的事件处理器，如 `onicecandidate` (处理 ICE 候选者)、`onicegatheringstatechange` (处理 ICE 收集状态变化)、`onconnectionstatechange` (处理整体连接状态变化) 以及 `ondatachannel` (处理对方发起的数据通道)。
        *   调用 `dataChannel = pc.createDataChannel('chatChannel', {reliable: true})` 创建一个用于文本聊天和信令的可靠数据通道。
        *   调用 `this.setupDataChannel(dataChannel, targetPeerId)` 为新创建的数据通道设置事件处理器，包括 `onopen` (通道打开时)、`onmessage` (收到数据时)、`onclose` (通道关闭时) 和 `onerror` (发生错误时)。
        *   调用 `offer = await pc.createOffer()` 生成 SDP (会话描述协议) 提议。
        *   调用 `await pc.setLocalDescription(offer)` 将生成的提议设置为本地描述。
        *   通过 `this.sendSignalingMessage({ type: 'OFFER', userId: UserA_ID, targetUserId: UserB_ID, sdp: offer.sdp, candidates: [...] }, isSilent)` 将 SDP 提议和已收集到的 ICE 候选者通过 WebSocket 发送给信令服务器，由服务器转发给用户 B。
        *   在 `pc.onicecandidate` 事件中，当浏览器发现新的本地 ICE 候选者时，会通过 `sendSignalingMessage({ type: 'ICE_CANDIDATE', ... })` 陆续将其发送给用户 B。

4.  **用户 B 处理提议并发送应答 (主要在 `ConnectionManager.js` 中进行):**
    *   信令服务器将用户 A 发送的 `OFFER` 消息转发给用户 B。
    *   用户 B 的 `websocket.onmessage` 事件处理器接收到该消息，并调用 `handleSignalingMessage(message)`。
    *   `handleSignalingMessage(message)` 方法中：
        *   对于 `type: 'OFFER'` 类型的消息，调用 `this.handleRemoteOffer(fromUserId = UserA_ID, message.sdp, message.candidates, false, ...)`。
            *   `handleRemoteOffer()` 方法内部：
                *   调用 `pc = this.initConnection(fromUserId, false)` 初始化或获取与用户 A 的 `RTCPeerConnection` 实例。
                *   设置 `pc.ondatachannel` 事件处理器，以准备接收用户 A 创建的数据通道。
                *   调用 `await pc.setRemoteDescription(new RTCSessionDescription({type: 'offer', sdp: message.sdp}))` 将收到的提议设置为远端描述。
                *   如果消息中包含 `candidates` (ICE 候选者列表)，则逐个调用 `pc.addIceCandidate()` 添加它们。
                *   调用 `answer = await pc.createAnswer()` 生成 SDP 应答。
                *   调用 `await pc.setLocalDescription(answer)` 将生成的应答设置为本地描述。
                *   通过 `this.sendSignalingMessage({ type: 'ANSWER', userId: UserB_ID, targetUserId: UserA_ID, sdp: answer.sdp, candidates: [...] })` 将 SDP 应答和已收集到的本地 ICE 候选者通过 WebSocket 发送给信令服务器，由服务器转发给用户 A。
                *   同样，在 `pc.onicecandidate` 事件中，用户 B 收集到的新 ICE 候选者也会陆续发送给用户 A。

5.  **用户 A 处理应答 (主要在 `ConnectionManager.js` 中进行):**
    *   信令服务器将用户 B 发送的 `ANSWER` 消息转发给用户 A。
    *   用户 A 的 `websocket.onmessage` 事件处理器接收到该消息，并调用 `handleSignalingMessage(message)`。
    *   `handleSignalingMessage(message)` 方法中：
        *   对于 `type: 'ANSWER'` 类型的消息，调用 `this.handleRemoteAnswer(fromUserId = UserB_ID, message.sdp, message.candidates, ...)`。
            *   `handleRemoteAnswer()` 方法内部：
                *   获取与用户 B 的 `RTCPeerConnection` 实例。
                *   调用 `await pc.setRemoteDescription(new RTCSessionDescription({type: 'answer', sdp: message.sdp}))` 将收到的应答设置为远端描述。
                *   如果消息中包含 `candidates`，则逐个添加。

6.  **ICE 候选者交换 (双方，主要在 `ConnectionManager.js` 中进行):**
    *   在整个协商过程中，双方都会通过信令服务器接收对方发送的 `ICE_CANDIDATE` (ICE候选者) 类型的消息。
    *   `handleSignalingMessage(message)` 对于 `type: 'ICE_CANDIDATE'` 类型的消息，会调用 `this.handleRemoteIceCandidate(fromUserId, message.candidate)`。
    *   `handleRemoteIceCandidate()` 方法内部调用 `pc.addIceCandidate(new RTCIceCandidate(candidate))` 将远端候选者添加到 `RTCPeerConnection` 中。

7.  **数据通道打开 (双方):**
    *   当 ICE 协商成功并且 WebRTC 连接路径建立后，之前创建的数据通道 (`chatChannel`) 会触发 `open` 事件。
    *   在 `ConnectionManager.js` 的 `setupDataChannel()` 方法中设置的 `channel.onopen` 事件处理器被调用：
        *   记录日志：“`ConnectionManager: 与 [对方名称] 的数据通道 ("[通道名称]") 已打开。`”
        *   如果当前聊天对象是对方，则更新聊天区域头部的状态显示：`ChatAreaUIManager.updateChatHeaderStatus('已连接到 [对方名称]')`。
        *   调用 `this._ensureContactExistsForPeer(finalPeerId, ...)` 确保（在手动连接或未知ID情况下）联系人记录存在。
        *   触发 `EventEmitter.emit('connectionEstablished', finalPeerId)` 事件，通知其他模块连接已建立。
        *   如果当前聊天是对方且不是视频通话，则启用通话按钮：`ChatAreaUIManager.setCallButtonsState(true, finalPeerId)`。
        *   重置与该对方的自动重连尝试次数：`this.reconnectAttempts[finalPeerId] = 0`。
    *   此时，用户 A 和用户 B 之间用于文本聊天的 WebRTC 数据通道已经成功建立。

**阶段一：呼叫发起 (用户 A 呼叫 用户 B)**

1.  **用户界面交互 (用户 A):**
    *   `ChatAreaUIManager.js` (聊天区域UI管理器): 用户 A 点击“**语音通话按钮**” (`audioCallButtonEl`)。
    *   `bindEvents` 中的事件监听器调用 `VideoCallManager.initiateAudioCall(ChatManager.currentChatId)` (其中 `currentChatId` 是用户 B 的 ID)。

2.  **通话逻辑启动 (用户 A 的 `VideoCallManager.js` - 视频通话管理器):**
    *   `initiateAudioCall(peerId)`: 调用 `this.initiateCall(peerId, true)` (true 代表纯音频通话)。
    *   `initiateCall(peerId, audioOnly = true)`:
        *   设置 `this.isAudioOnly = true` (纯音频), `this.isVideoEnabled = false` (视频禁用)。
        *   设置 `this.currentPeerId = peerId` (用户 B 的 ID)。
        *   设置 `this.isCaller = true` (用户 A 是呼叫发起方)。
        *   设置 `this.isCallPending = true` (呼叫等待中)。
        *   通过 **`ConnectionManager.sendTo(peerId, { type: 'video-call-request', audioOnly: true, isScreenShare: false, sender: UserManager.userId })`** 将呼叫请求信令消息通过已建立的 WebRTC 数据通道发送给用户 B。
        *   调用 `ModalUIManager.showCallingModal(UserManager.contacts[peerId]?.name || '对方', onCancelCall, onStopMusic, '**语音通话**')`。这将显示一个模态框，内容为：“**语音通话... 正在联系 [用户 B 的名称]...**”。
        *   调用 `this.playMusic()` 播放呼叫音乐 (`Config.music`, 即 `call.mp3`)。
        *   设置 `this.callRequestTimeout` (例如，30秒后无应答则超时)。

**阶段二：呼叫请求接收 (用户 B)**

1.  **数据通道消息处理 (用户 B 的 `ConnectionManager.js` - 连接管理器):**
    *   `setupDataChannel` 的 `onmessage` 处理器接收到来自用户 A 的 `video-call-request` (视频通话请求) 类型的消息 (通过数据通道)。
    *   该消息被路由到 `VideoCallManager.handleMessage(message, peerId)` 进行处理。

2.  **呼叫请求处理 (用户 B 的 `VideoCallManager.js`):**
    *   `handleMessage(message, peerId)` 处理 `type: 'video-call-request'`:
        *   检查用户 B 当前是否不在通话中 (`!this.isCallActive && !this.isCallPending`)。
        *   设置 `this.isCallPending = true`。
        *   调用 `this.showCallRequest(peerId, message.audioOnly, message.isScreenShare)`。
        *   `showCallRequest(peerId, audioOnly = true, isScreenShare = false)`:
            *   设置 `this.currentPeerId = peerId` (用户 A 的 ID)。
            *   设置 `this.isAudioOnly = true`, `this.isCaller = false` (用户 B 是接收方)。
            *   调用 `ModalUIManager.showCallRequest(peerId, true, false)`。这将显示一个来电请求模态框，标题为“**语音通话请求**”，内容为“**[用户 A 的名称] 正在呼叫...**”，并带有“**接听**”和“**拒绝**”按钮。
            *   调用 `this.playMusic()` 播放来电铃声。

**阶段三：呼叫接听 (用户 B 接听)**

1.  **用户界面交互 (用户 B):**
    *   `ModalUIManager.js` (模态框UI管理器): 用户 B 在 `videoCallRequestModal` (来电请求模态框) 中点击“**接听**”按钮。
    *   `ModalUIManager.showCallRequest` 中设置的事件监听器调用 `VideoCallManager.acceptCall()`。

2.  **呼叫接听逻辑 (用户 B 的 `VideoCallManager.js`):**
    *   `acceptCall()`:
        *   调用 `ModalUIManager.hideCallRequest()` 隐藏来电请求模态框。
        *   调用 `this.stopMusic()` 停止播放铃声。
        *   调用 `this.startLocalStreamAndSignal(false)` (参数 `false` 表示用户 B 不是媒体协商的初始提议方)。
            *   `startLocalStreamAndSignal(isOfferCreatorForMedia = false)`:
                *   由于 `this.isAudioOnly` 为 `true`，`attemptLocalCameraVideoSending` 将为 `false`。
                *   `this.localStream = await navigator.mediaDevices.getUserMedia({ video: false, audio: this.audioConstraints })` 获取本地麦克风权限和音频流。
                *   调用 `VideoCallUIManager.setLocalStream(this.localStream)` 将本地流设置到UI。
                *   调用 `VideoCallUIManager.showCallContainer(true)` 显示通话中的UI界面。
                *   设置 `this.isCallActive = true` (通话激活), `this.isCallPending = false`。
                *   调用 `this.updateCurrentCallUIState()` 更新通话控制按钮（静音、摄像头等）的状态。
                *   调用 `this.setupPeerConnection(false)`。
                    *   `setupPeerConnection(isOfferCreatorForMedia = false)`:
                        *   从 `ConnectionManager.connections[peerId]` 获取与用户 A 的 **已存在的 `RTCPeerConnection` (`pc`) 实例**。此实例之前用于数据通道。
                        *   将本地音频轨道 (`this.localStream` 中的轨道) 添加到 `pc`。
                        *   调用 `this.setCodecPreferences(pc)` 设置音频编解码器偏好 (如 Opus)。
                        *   设置 `pc.ontrack` 事件处理器，用于处理从用户 A 接收到的远端媒体流。
                        *   调用 `this.setupConnectionMonitoring(pc)`。
                        *   **由于 `isOfferCreatorForMedia` 为 `false`，不调用 `createAndSendOffer()`。用户 B 现在等待用户 A 发送媒体提议 (Offer)。**
        *   通过 `ConnectionManager.sendTo(this.currentPeerId, { type: 'video-call-accepted', audioOnly: true, ... })` 向用户 A 发送通话已接听的信令消息 (通过数据通道)。

**阶段四：呼叫接听确认与媒体提议 (用户 A)**

1.  **数据通道消息处理 (用户 A 的 `ConnectionManager.js`):**
    *   `setupDataChannel` 的 `onmessage` 处理器接收到来自用户 B 的 `video-call-accepted` (视频通话已接受) 类型的消息。
    *   该消息被路由到 `VideoCallManager.handleMessage(message, peerId)`。

2.  **接听确认处理与媒体提议创建 (用户 A 的 `VideoCallManager.js`):**
    *   `handleMessage(message, peerId)` 处理 `type: 'video-call-accepted'`:
        *   停止播放呼叫音乐，隐藏“正在呼叫”模态框，清除呼叫请求超时。
        *   调用 `this.startLocalStreamAndSignal(true)` (参数 `true` 表示用户 A 作为原始呼叫方，现在将创建媒体提议)。
            *   `startLocalStreamAndSignal(isOfferCreatorForMedia = true)`:
                *   获取本地麦克风音频流 (过程类似用户 B)。
                *   显示通话中UI，设置 `isCallActive = true` 等。
                *   调用 `this.setupPeerConnection(true)`。
                    *   `setupPeerConnection(isOfferCreatorForMedia = true)`:
                        *   获取与用户 B 的 **已存在的 `RTCPeerConnection` (`pc`) 实例**。
                        *   添加本地音频轨道，设置编解码器偏好，设置 `pc.ontrack`。
                        *   **由于 `isOfferCreatorForMedia` 为 `true`，调用 `this.createAndSendOffer()`。**
                            *   `createAndSendOffer()`:
                                *   调用 `this._applyAudioProfileToSender(...)` 应用初始音频配置档案。
                                *   `offer = await pc.createOffer(...)` 创建SDP提议。
                                *   `modifiedOfferSdp = this.modifySdpForOpus(offer.sdp, this.currentPeerId)` 修改SDP，为Opus编解码器设置特定参数 (如ptime, FEC, stereo=0)。
                                *   `await pc.setLocalDescription(new RTCSessionDescription({type: 'offer', sdp: modifiedOfferSdp}))` 设置本地描述。
                                *   设置 `this._lastNegotiatedSdpFmtpLine[this.currentPeerId]` 以记录当前协商的 Opus 参数。
                                *   通过 `ConnectionManager.sendTo(this.currentPeerId, { type: 'video-call-offer', sdp: pc.localDescription, audioOnly: true, ... })` 向用户 B 发送媒体提议信令 (通过数据通道)。

**阶段五：媒体应答 (用户 B)**

1.  **数据通道消息处理 (用户 B 的 `ConnectionManager.js`):**
    *   `setupDataChannel` 的 `onmessage` 处理器接收到来自用户 A 的 `video-call-offer` (视频通话提议) 类型的消息。
    *   该消息被路由到 `VideoCallManager.handleMessage(message, peerId)`。

2.  **媒体提议处理与应答创建 (用户 B 的 `VideoCallManager.js`):**
    *   `handleMessage(message, peerId)` 处理 `type: 'video-call-offer'`:
        *   调用 `this.handleOffer(message.sdp, peerId, message.audioOnly, ...)`。
            *   `handleOffer(sdpOffer, peerId, remoteIsAudioOnly, ...)`:
                *   获取与用户 A 的 `pc`。
                *   `await pc.setRemoteDescription(new RTCSessionDescription(sdpOffer))` 设置远端描述。
                *   调用 `this._applyAudioProfileToSender(...)`。
                *   `answer = await pc.createAnswer()` 创建SDP应答。
                *   `modifiedAnswerSdp = this.modifySdpForOpus(answer.sdp, peerId)` 修改应答SDP以匹配Opus参数。
                *   `await pc.setLocalDescription(new RTCSessionDescription({type: 'answer', sdp: modifiedAnswerSdp}))` 设置本地描述。
                *   设置 `this._lastNegotiatedSdpFmtpLine[peerId]`。
                *   通过 `ConnectionManager.sendTo(peerId, { type: 'video-call-answer', sdp: pc.localDescription, audioOnly: true, ... })` 向用户 A 发送媒体应答信令 (通过数据通道)。
                *   调用 `this._startAdaptiveAudioCheck(peerId)` 开始监控网络状况以进行自适应音频质量调整。

**阶段六：媒体应答确认 (用户 A)**

1.  **数据通道消息处理 (用户 A 的 `ConnectionManager.js`):**
    *   `setupDataChannel` 的 `onmessage` 处理器接收到来自用户 B 的 `video-call-answer` (视频通话应答) 类型的消息。
    *   该消息被路由到 `VideoCallManager.handleMessage(message, peerId)`。

2.  **媒体应答处理 (用户 A 的 `VideoCallManager.js`):**
    *   `handleMessage(message, peerId)` 处理 `type: 'video-call-answer'`:
        *   调用 `this.handleAnswer(message.sdp, peerId, ...)`。
            *   `handleAnswer(sdpAnswer, peerId, ...)`:
                *   获取与用户 B 的 `pc`。
                *   `await pc.setRemoteDescription(new RTCSessionDescription(sdpAnswer))` 设置远端描述。
                *   调用 `this._startAdaptiveAudioCheck(peerId)` 开始监控网络状况。

**阶段七：通话连接与进行中**

*   **媒体流建立：**
    *   ICE (交互式连接建立) 候选者已经通过 WebSocket 信令服务器交换完成。
    *   `RTCPeerConnection` 的连接状态（`pc.connectionState`）变为 `connected` (已连接)。
    *   双方的本地音频流 (`localStream`) 中的音轨现在开始通过已建立的 WebRTC 连接进行双向传输。
*   **用户界面 (双方):**
    *   `VideoCallUIManager.js` (视频通话UI管理器):
        *   在 `VideoCallManager.setupPeerConnection` 中设置的 `pc.ontrack` 事件会在接收到对方的音频轨道时触发。
        *   处理器内部会调用 `VideoCallUIManager.setRemoteStream()`，将远端媒体流（包含对方的音频）赋予 UI 中的远程音频播放元素 (通常是一个背景播放的 `<audio>` 标签)。
        *   `updateUIForCallState` 方法被调用，显示激活的通话控制按钮，例如“**静音**”/“**取消静音**” (`toggleAudioBtn`) 和 “**挂断**” (`endCallBtn`)。本地视频元素 (`localVideo`) 保持隐藏，因为这是纯音频通话。
*   **自适应音频质量 (双方，由 `VideoCallManager.js` 管理):**
    *   `_startAdaptiveAudioCheck(peerId)` 方法已在双方处理完 Offer/Answer 后启动了一个定时器。
    *   `_checkAndAdaptAudioQuality(peerId)` 方法会周期性执行：
        *   通过调用 `pc.getStats()` 获取当前的 WebRTC 网络统计数据，如 RTT (往返时间)、packetLoss (丢包率)、jitter (抖动)。
        *   `_determineOptimalQualityLevel(...)` 方法根据这些统计数据和预设的阈值 (来自 `Config.adaptiveAudioQuality.baseGoodConnectionThresholds`) 来判断当前网络状况是否适合提升或需要降低音频质量。
        *   如果判断需要调整音频质量配置档案，并且相关的冷却时间 (如 `switchToHigherCooldown`, `switchToLowerCooldown`) 已过，则调用 `_switchToAudioProfile(peerId, newLevelIndex)` 方法。
            *   `_switchToAudioProfile()`:
                *   更新内部状态 `_currentAudioProfileIndex[peerId]` 来记录新的音频配置档案索引。
                *   获取新配置档案中定义的 `sdpFmtpLine` (Opus 参数字符串)。
                *   **关键点：** 如果新的 `sdpFmtpLine` 与 `_lastNegotiatedSdpFmtpLine[peerId]` (上次成功协商的参数) 不同，并且当前客户端是原始呼叫的发起方 (`this.isCaller` 为 `true`，在此场景中是用户 A)，则会调用 `_initiateRenegotiation(peerId)` 来发起一次 WebRTC 重新协商。
                    *   `_initiateRenegotiation()` 内部会再次调用 `createAndSendOffer()`，这将生成一个新的 SDP Offer，其中包含由 `modifySdpForOpus` 根据新音频配置档案修改过的 Opus 参数。这个新的 Offer 会通过数据通道发送给对方，触发一次简短的 Offer/Answer 交换，以更新媒体流参数。
                *   调用 `_applyAudioProfileToSender(...)`，该方法可能会尝试直接修改 `RTCRtpSender` 的参数 (如 `maxBitrate`)，如果这些参数的改变不需要完整的 SDP 重新协商。
                *   触发 `EventEmitter.emit('audioProfileChanged', { peerId, profileName, profileIndex, description })` 事件。
                    *   `VideoCallUIManager.js` 中的 `_updateAudioQualityDisplay` 方法监听到此事件，并根据 `data.profileName` (例如：“**标准**”、“**较高**”、“**较低**”，这些文本来自 `Config.adaptiveAudioQuality.audioQualityProfiles[n].levelName`) 和 `data.profileIndex` 更新音频质量指示器 (`audioQualityIndicatorEl`) 的文本内容和 CSS 类，向用户展示当前的音频质量级别。其 `title` 属性也会根据 `data.description` 更新，提供更详细的说明。

**阶段八：通话挂断 (用户 A 挂断)**

1.  **用户界面交互 (用户 A):**
    *   `VideoCallUIManager.js`: 用户 A 点击通话界面中的“**挂断**”按钮 (`endCallBtn`)。
    *   该按钮的事件监听器调用 `VideoCallManager.hangUpMedia()`。

2.  **挂断逻辑 (用户 A 的 `VideoCallManager.js`):**
    *   `hangUpMedia(notifyPeer = true)`:
        *   调用 `_stopAdaptiveAudioCheck(this.currentPeerId)` 停止对当前对方的自适应音频质量检测。
        *   如果 `notifyPeer` 为 `true` (默认)，则通过 `ConnectionManager.sendTo(this.currentPeerId, {type: 'video-call-end', sender: UserManager.userId})` 向用户 B 发送 `video-call-end` (视频通话结束) 类型的信令消息 (通过数据通道)。
        *   调用 `this.cleanupCallMediaAndState(false)` (参数 `false` 表示不一定立即关闭底层的 `RTCPeerConnection`，因为数据通道可能仍需用于文本聊天；但与通话相关的媒体轨道会被停止和清理)。
            *   `cleanupCallMediaAndState()`:
                *   调用 `this.stopMusic()` 停止任何可能在播放的呼叫音乐。
                *   调用 `ModalUIManager.hideCallingModal()` 和 `ModalUIManager.hideCallRequest()` 隐藏所有通话相关的模态框。
                *   调用 `this.releaseMediaResources()`，这将停止本地音频流 (`this.localStream`) 中的所有轨道。
                *   调用 `VideoCallUIManager.setLocalStream(null)` 和 `VideoCallUIManager.setRemoteStream(null)` 清除 UI 上的本地和远程媒体流显示。
                *   调用 `VideoCallUIManager.showCallContainer(false)` 隐藏整个通话 UI 容器。
                *   重置通话相关的内部状态变量，如 `isCallActive = false`, `isAudioOnly = false`, `currentPeerId = null` 等。
                *   调用 `VideoCallUIManager.updateUIForCallState()`，这将根据重置后的状态进一步更新 UI (例如，隐藏通话按钮)。
                *   **注意：** 由于 `closePeerConnectionIfUnused` 为 `false`，通常不会在这里调用 `ConnectionManager.closePeerConnection()`。底层的 WebRTC 连接和数据通道会保持，以便用户可以继续进行文本聊天。

**阶段九：通话结束接收 (用户 B)**

1.  **数据通道消息处理 (用户 B 的 `ConnectionManager.js`):**
    *   `setupDataChannel` 的 `onmessage` 处理器接收到来自用户 A 的 `video-call-end` 类型的信令消息。
    *   该消息被路由到 `VideoCallManager.handleMessage(message, peerId)`。

2.  **结束通话处理 (用户 B 的 `VideoCallManager.js`):**
    *   `handleMessage(message, peerId)` 处理 `type: 'video-call-end'`:
        *   调用 `NotificationUIManager.showNotification("[用户 A 的名称] **结束了通话媒体**。", "info")` 向用户 B 显示一条通知。
        *   调用 `this.cleanupCallMediaAndState(false)` (与用户 A 执行基本相同的清理流程，停止本地媒体，清除UI，重置状态)。

**涉及的中文界面/通知元素回顾：**

*   **按钮与标签：** “语音通话按钮”、“接听”、“拒绝”、“静音”、“取消静音”、“挂断”。
*   **模态框文本：** “语音通话... 正在联系 [对方名称]...”、“语音通话请求 来自 [对方名称]”。
*   **通知消息：** “[对方名称] 结束了通话媒体。”
*   **音频质量指示器：** 显示如“标准”、“较高”、“较低”等文本，工具提示中可能包含“一般网络，标准音质”、“优秀网络，最佳音质”等来自 `Config.js` 中 `adaptiveAudioQuality.audioQualityProfiles` 的描述。

这个详尽的流程涵盖了从初始网络连接到语音通话建立、进行中（包括动态质量调整）及最终挂断的各个环节，并突出了中文界面元素和用户反馈。